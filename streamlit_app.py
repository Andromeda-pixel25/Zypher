import streamlit as st
import os
import requests
import pyttsx3
from streamlit_mic_recorder import mic_recorder, speech_to_text
from audio_recorder_streamlit import audio_recorder

# Initialize pyttsx3 engine
engine = pyttsx3.init()

def speak(text):
    engine.say(text)
    engine.runAndWait()

def role_to_streamlit(role):
    return "assistant" if role == "model" else role

if "messages" not in st.session_state:
    st.session_state.messages = []

def render_chat_history():
    for message in st.session_state.messages:
        role, text = message
        with st.chat_message(role):
            st.markdown(text)

def get_serverless_response(prompt):
    url = "https://api-inference.huggingface.co/models/gpt2"
    headers = {"Authorization": "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"}
    payload = {"inputs": prompt}
    response = requests.post(url, headers=headers, json=payload)
    return response.json()["generated_text"] if response.status_code == 200 else "Error: Unable to fetch response."

# Pages
pages = ["Text Response", "Voice Recognition", "Image Generation"]
st.sidebar.title("ZypherAi Navigation")
selected_page = st.sidebar.radio("Go to", pages)

if selected_page == "Text Response":
    st.title("ZypherAi - Text Response")
    st.markdown("Powered by Serverless Inference API")
    render_chat_history()
    prompt_text = st.chat_input("Ask away...")
    if prompt_text:
        st.chat_message("user").markdown(prompt_text)
        with st.spinner("Zypher is thinking..."):
            response = get_serverless_response(prompt_text)
            st.session_state.messages.append(("assistant", response))
            with st.chat_message("assistant"):
                st.markdown(response)
            speak(response)

elif selected_page == "Voice Recognition":
    st.title("ZypherAi - Voice Recognition")
    st.markdown("Talk to Zypher using your voice")
    footer_container = st.container()
    with footer_container:
        audio_bytes = audio_recorder()
    if audio_bytes:
        with st.spinner("Transcribing..."):
            webm_file_path = "temp_audio.mp3"
            with open(webm_file_path, "wb") as f:
                f.write(audio_bytes)
            transcript = speech_to_text(webm_file_path)
            if transcript:
                st.chat_message("user").write(transcript)
                with st.spinner("Zypher is thinking..."):
                    response = get_serverless_response(transcript)
                    st.session_state.messages.append(("assistant", response))
                    with st.chat_message("assistant"):
                        st.markdown(response)
                    speak(response)
                os.remove(webm_file_path)
            else:
                st.error("Could not transcribe the audio. Please try again.")

elif selected_page == "Image Generation":
    st.title("ZypherAi - Image Generation")
    st.markdown("Generate images from text prompts.")
    user_prompt = st.text_input("Describe the image you want to generate:")
    if st.button("Generate Image"):
        with st.spinner("Zypher is creating your image..."):
            try:
                response = requests.post(
                    "https://api-inference.huggingface.co/models/stable-diffusion-v1-4",
                    headers={"Authorization": "Bearer YOUR_HUGGINGFACE_API_KEY"},
                    json={"inputs": user_prompt}
                )
                image_url = response.json().get("generated_image_url", "")
                if image_url:
                    st.image(image_url, caption="Generated by Zypher")
                else:
                    st.error("Image generation failed: " + response.text)
            except Exception as e:
                st.error("Image generation failed: " + str(e))

st.sidebar.markdown("---")
st.sidebar.text("ZypherAi")
st.sidebar.text("Created by: [Your Name]")
